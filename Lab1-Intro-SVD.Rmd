---
title: "Analysis of High Dimensional Data - Lab 1"
author: "Adapted by Milan Malfait"
date: "15 Oct 2020"
output:
    html_document:
      code_download: true
      theme: cosmo
      toc: true
      toc_float: true
      highlight: tango
      number_sections: true
---

```{r setup, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

***

# Introduction

The purpose of the following exercises is mainly to get more familiar with SVD and its applications,
in particular Multidimensional Scaling (MDS).
It is recommended to perform the exercises in an [`RMarkdown`][rmarkdown] document.

For a brief introduction to RMarkdown, see [Introduction to RMarkdown](./Introduction-RMarkdown.html).

For an introduction to working with matrices in R, see [Working with Matrices in R](./Introduction-Matrices-R.html).


## Libraries {-}

Packages used in this document.
Installation code is commented, uncomment and paste this code in an R console to install the packages.

```{r libraries, message=FALSE, warning=FALSE}
# install.packages(c("tidyverse", "ggfortify"))
library(tidyverse)
library(ggfortify)
```



# Multidimensional Scaling (MDS) demonstration

See [course notes](https://statomics.github.io/HDA2020/pages/svd.html#7_SVD_and_Multi-Dimensional_Scaling_(MDS)) for background.


* We will use `UScitiesD` data as an example
* Our goal is to use the distance matrix $\mathbf D_X$  without knowledge of $\mathbf X$ to represent the rows of $\mathbf X$ in a low dimensional space, say 2D or 3D. 
* We search for $\mathbf V_k$ that orthogonally project the rows of $\mathbf X$, $\mathbf x^t_i$  onto a $k-D$ space spanned by the columns of $\mathbf V_k$. In fact we are looking for $\mathbf Z_k$, such that $\mathbf Z_k=\mathbf X \mathbf V_k$
*  But we do not know $\mathbf X$, so how do we get $\mathbf Z_k$? We will use the $\mathbf G_X$ (gram matrix) trick, mentioned in the course notes


## Example: Distances between US cities

As an example, we will use the `UScitiesD` data set, which is part of base R.
This data gives "straight line" distances (in km) between 10 cities in the US.

```{r}
UScitiesD
class(UScitiesD)
```

Note that the `UScitiesD` object is of class `"dist"`, which is a special type of object to represent that it is a __distance matrix__ (we'll denote this as $\mathbf{D}_X$), i.e. the result from computing distances from an original matrix $\mathbf{X}$.
In this case, the original matrix $\mathbf{X}$ was likely a matrix with a row for every city and columns specifying its coordinates.
Note though that we don't know $\mathbf{X}$ exactly.
Still, we can use the distance matrix and MDS to approximate a low-dimensional representation of $\mathbf{X}$.


### Exploring the distance matrix

We first convert the `UScitiesD` to a matrix for easier manipulation and calculation.
Note that this creates a "symmetrical" matrix, with 0s on the diagonal (distance of a city to itself).

```{r}
(dist_mx <- as.matrix(UScitiesD))
```

The dimensions of `dist_mx`:

```{r}
# 10 x 10 square matrix
dim(dist_mx)
```
And the rank of `dist_mx`

```{r} 
qr(dist_mx)$rank
```

>Q: is this matrix of full rank?

<details><summary>Answer</summary>
A: Yes, it is.

```{r}
qr(dist_mx)$rank == min(dim(dist_mx))
```

</details>



### $\mathbf{H}$ and $\mathbf{G}_X$ matrices

Now let's create the $\mathbf  H$ matrix.

$$ \mathbf{H} = \mathbf{I}_{n \times n} - \frac{1}{n} \mathbf{1}_n\mathbf{1}_n^T $$
```{r H_matrix}
n <- nrow(dist_mx)

# 11^T
(one_mat <- matrix(rep(1, n * n), ncol = n, nrow = n))
## Alternatively: one_mat <- rep(1, n) %o% rep(1, n)

## Calculate H, diag(n) is the nxn identity matrix
(H <- diag(n) - (1/n) * one_mat)
```

We can use $\mathbf{H}$ to center our distance matrix:

```{r dist_mx_centered}
(dist_mx_centered <- H %*% dist_mx)
round(colMeans(dist_mx_centered), 8)  # verify colMeans are 0
```

We will use this matrix to calculate $\mathbf{G}_X$ (Gram matrix of $\mathbf{X}$).

$$
\mathbf{G}_X = -\frac{1}{2}\mathbf{H}\mathbf{D}_X\mathbf{H} = \mathbf{X}\mathbf{X}^T
$$

Where $\mathbf{D}_X$ is the matrix of __*squared* distances__.
So we will first have to square our `dist_mx`.

```{r Gram_matrix}
## D_X = squared distance matrix
D_X <- dist_mx ^ 2

## Gram matrix
(G_X <- -1/2 * H %*% (D_X) %*% H)
```


### The SVD

We can now compute the SVD of the Gram matrix and use it to project our original matrix $\mathbf{X}$ (which is still unknown to us!) into a lower dimensional space while preserving the Euclidean distances as well as possible.
This is the essence of MDS.

```{r GX matrix}
## singular value decomposition on gram matrix
Gx_svd <- svd(G_X)

## Use `str` to explore structure of the SVD object
str(Gx_svd)
```

Components of the `Gx_svd` object:

- `Gx_svd$d`: diagonal elements of the $\mathbf{\Delta}$ matrix, to recreate the matrix, use the `diag()` function
- `Gx_svd$u`: the matrix $\mathbf{U}$ of left singular vectors
- `Gx_svd$v`: the matrix $\mathbf{V}$ of right singular vectors


### Truncated SVD and projection into lower dimensional space

The truncated SVD from the Gram matrix can be used to find projections $Z_k$ of $\mathbf{X}$ in a lower dimensional space.
Here we will use $k = 2$.

```{r}
# k=2 approximation
k <- 2
Uk <- Gx_svd$u[, 1:k]
delta_k <- diag(Gx_svd$d[1:k])
Zk <- Uk %*% sqrt(delta_k)
rownames(Zk) <- colnames(D_X)
colnames(Zk) <- c("Z1", "Z2")
Zk

# Plotting Zk in 2-D

## Using base R
# plot(Zk, type = "n", xlab = "Z1", ylab = "Z2", xlim = c(-1500, 1500))
# text(Zk, rownames(Zk), cex = 1.25)

## Using ggplot, by first converting Zk to a tibble
Zk %>%
  # create tibble and change rownames to column named "city"
  as_tibble(rownames = "city") %>% 
  ggplot(aes(Z1, Z2, label = city)) +
    geom_point() +
    # adding the city names as label 
    geom_text(nudge_y = 50) +
    # setting limits of the x-axis to center the plot around 0
    xlim(c(-1500, 1500)) +
    ggtitle("MDS plot of the UScitiesD data") +
    theme_minimal()
```

What can you say about the plot? 
Think about the real locations of these cities on a map of the US.

<details><summary>Answer</summary>
$Z_1$ can be interpreted as the *longitude*, i.e. the East-West position.
$Z_2$ reflects the *latitude*, or the North-South position.
</details>


## The short way

The calculations above demonstrate how MDS works and what the underlying components are.
However, in a real data analysis, one would typically not go through all the hassle of calculating all the intermediate steps.
Fortunately, the MDS is already implemented in base R (in the `stats` package).

So the whole derivation we did above can be reproduced with a single line of code, using the `cmdscale` function (see `?cmdscale` for details).

```{r}
## Calculate MDS in 2 dimensions from distance matrix
(us_mds <- cmdscale(UScitiesD, k = 2))
colnames(us_mds) <- c("Z1", "Z2")

## Plot MDS
us_mds %>% 
  as_tibble(rownames = "city") %>% 
  ggplot(aes(Z1, Z2, label = city)) +
  geom_point() +
  geom_text(nudge_y = 50) +
  xlim(c(-1500, 1500)) +
  theme_minimal()
```

Which gives us the same result as before (which is a good check that we didn't make mistakes!).




###Exercise: Cheese data 
Read in the data
```{r CheeseData}
Cheese <- read.csv("cheese.csv", header=TRUE)
head(Cheese)

#assigning row names
rownames(Cheese) <-paste("case",1:dim(Cheese)[1])
X.orig <- Cheese[ , -1]
X.orig[,1:4]
rankMatrix(X.orig)[[1]] 
n <- nrow(X.orig)

# Centering the data matrix
H <- diag(n) -1/n*matrix(1, ncol=n, nrow=n)
X <- H %*% as.matrix(X.orig)

```

1.  Earlier, we obtained the column-centered data matrix $\mathbf{X}$ after multiplying $\mathbf{X.orig}$ with
$$
   \mathbf{H} = \mathbf{I} - \frac{1}{n} \mathbf{1}\mathbf{1}^t ,
$$

+ Demonstrate that $\mathbf{X}$ is indeed column-centered (and not row-centered). 

```{r demonstrate column center,echo=FALSE,results=FALSE}
# X is indeed column-centered:
colMeans(X)

# but it is not row-centered:
 rowMeans(X)
```

+ Verify that whenever $\mathbf{X}$ is column-centered, the equality $\mathbf{HX = X}$ holds.
```{r,echo=FALSE,results=FALSE}
# verifying that HX = X i.e HX-X=0 matrix
H %*% X-X
```
+ Repeat the SVD of $\mathbf{X}$, and store the matrices $\mathbf{U}$, $\mathbf{V}$ and $\mathbf{D}$ as separate ```R```-objects.
```{r SVD,echo=FALSE,results=FALSE}
 # The Singular Value Decomposition of X
# =====================================
X.svd <- svd(X)
str(X.svd)
U <- X.svd$u
V <- X.svd$v
D <- diag(X.svd$d)
```
  
2. Show that $\mathbf{u_1}$ is a normalized vector; show the same for $\mathbf{u_2}$. Show that $\mathbf{u_1}$ and $\mathbf{u_2}$ are orthogonal vectors. Then show the orthonormality of all vectors $\mathbf{u_j}$ in a single calculation (using the matrix $\mathbf{U}$). Similarly, show the orthonormality of all vectors $\mathbf{v_j}$ in a single calculation (using the matrix $\mathbf{V}$). Did you obtain the result you expected? If not, explain.
```{r orthonorlity,echo=FALSE,results=FALSE}
# Verifying orthonormality
# ------------------------
# The vectors u1 and u2 are orthonormal
t(U[,1]) %*% U[,1]
t(U[,2]) %*% U[,2]
t(U[,1]) %*% U[,2]

# Verifying that U forms an orthonormal basis in one step:
t(U) %*% U   # computational imperfections
round(t(U) %*% U, digits=15)
 
 
# Verifying that V forms an orthonormal basis:
t(V) %*% V   # computational imperfections
round(t(V) %*% V, digits=15)
```

3.  Check that ```R``` has performed the SVD correctly, i.e. calculate the matrix $\mathbf{X}$ from the elements of the SVD. Do this in two different ways:

+ via the sum definition of the SVD (course notes p. 18) 
```{r SVD calculations,echo=FALSE,results=FALSE}
# Calculating X via the sum definition of the SVD:
# ------------------------------------------------
X.sum <- matrix(0, nrow=nrow(X), ncol=ncol(X))
X.sum
for (j in 1:ncol(U))
{ 
  X.sum <- X.sum + (X.svd$d[j]* U[,j] %*% t(V[,j]))
}
X.sum
```

+ via the matrix notation of the SVD (course notes. 19)
```{r,echo=FALSE,results=FALSE}
# Calculating X via the SVD matrix multiplication:
# ------------------------------------------------
X.mult <- U %*% D %*% t(V)
X.mult
```

+ Verify that the obtained results are identical to the  matrix $\mathbf{X}$.
```{r,echo=FALSE,results=FALSE}
round(X.sum-X,digits = 10)    # for comparison
```
4. Calculate the matrix $\mathbf{X_k}$, for $k = 2$. Do this again:
+ via the sum definition of the SVD (course notes  p. 18) 
```{r,echo=FALSE,results=FALSE}
# Calculating Xk (for k=2)
# ========================
# Calculating Xk via the sum definition of the SVD:
# -------------------------------------------------
Xk.sum <- matrix(0, nrow=nrow(X), ncol=ncol(X))
Xk.sum
for (j in 1:2)
{ 
  Xk.sum <- Xk.sum + (X.svd$d[j]* U[,j] %*% t(V[,j]))
}
Xk.sum
```
+ via the matrix notation of the SVD (course notes p. 19)
```{r,echo=FALSE,results=FALSE}
# Calculating Xk via the SVD matrix multiplication:
# -------------------------------------------------
Xk.mult <- U[, 1:2] %*% D[1:2,1:2] %*% t(V[,1:2])
Xk.mult
```

+ Compare the obtained results with the matrix $\mathbf{X}$. Just at a first glance, does it seem that $\mathbf{X_2}$ is an approximation of $\mathbf{X}$?



###Exercise: employment by industry

###In this exercise we will focus on the interpretation of the biplot.

The file ```Industries.txt``` contains data on the distribution of employment between 9 industrial sectors, in 26 European countries. The dataset stems from the Cold-War era; the data are expressed as percentages. Read in the data and have a feel about it. 
```{r,echo=FALSE,results=FALSE}
Indus <- read.table("Industries.txt", sep=" ", header=TRUE)
#First 6 rows of data.frame are displayed
head(Indus)

#assign row names
rownames(Indus) <- Indus$country

#delete the first column we will not need it.
X.orig <- Indus[ , -1]

#visualise
head(X.orig)

#Check the dimension
dim(X.orig)

#and then the rank
rankMatrix(X.orig)[[1]] 

#n will be used subsequently
n <- nrow(X.orig)
```


1. Perform the truncated SVD for $k=2$, and construct the biplot accordingly.
```{r,echo=FALSE,results=FALSE}
# Centering the data matrix first
H <- diag(n) -1/n*matrix(1, ncol=n, nrow=n)
X <- H %*% as.matrix(X.orig)
```

```{r,echo=FALSE,results=FALSE}
# Singular Value Decomposition is performed
X.svd <- svd(X)
X.svd
k <- 3
Uk <- X.svd$u[ , 1:k]
Dk <- diag(X.svd$d[1:k])
Zk <- Uk %*% Dk
rownames(Zk) <- Indus$country
Zk
```

```{r,echo=FALSE,results=FALSE}
#Prepare Vk
Vk <- X.svd$v[ , 1:k]
rownames(Vk) <- colnames(Indus[,-1])
Vk
```

```{r,echo=FALSE,results=FALSE}
# # Constructing the biplot for Z1 and Z2
#  # -------------------------------------
# plot(Zk[,1:2], type="n", xlim=c(-30,60), ylim=c(-15,15), 
#       xlab="Z1", ylab="Z2") 
# text(Zk[,1:2], rownames(Zk), cex=0.9)
# # alpha <- 1
# alpha <- 20  # rescaling to get better visualisation
# for(i in 1:9)
# { arrows(0,0, alpha*Vk[i,1], alpha*Vk[i,2], length=0.2, col=2)
#   text(alpha*Vk[i,1], alpha*Vk[i,2], rownames(Vk)[i], col=2)
# }
```

```{r,echo=FALSE,results=FALSE}
#  # Constructing the biplot for Z1 and Z3
# # -------------------------------------
# plot(Zk[,c(1,3)], type="n", xlim=c(-30,60), ylim=c(-15,15), 
#      xlab="Z1", ylab="Z3") 
# text(Zk[,c(1,3)], rownames(Zk), cex=0.9)
# # alpha <- 1
# alpha <- 20  # rescaling to get better visualisation
# for(i in 1:9)
# { arrows(0,0, alpha*Vk[i,1], alpha*Vk[i,3], length=0.2, col=2)
#    text(alpha*Vk[i,1], alpha*Vk[i,3], rownames(Vk)[i], col=2)
# }
 
```

```{r,echo=FALSE,results='hide'}
#  # Constructing the biplot for Z2 and Z3
#  # -------------------------------------
# plot(Zk[,2:3], type="n", xlim=c(-30,60), ylim=c(-15,15), 
#       xlab="Z2", ylab="Z3") 
# text(Zk[,2:3], rownames(Zk), cex=0.9)
# # alpha <- 1
# alpha <- 20  # rescaling to get better visualisation
# for(i in 1:9)
# { arrows(0,0, alpha*Vk[i,2], alpha*Vk[i,3], length=0.2, col=2)
#    text(alpha*Vk[i,2], alpha*Vk[i,3], rownames(Vk)[i], col=2)
# }
#  #We can also use inbuilt R functions for this.
# #--------------------------------------------
# #biplot()
```


2. To see if we can learn more when retaining more dimensions, repeat the truncated SVD for $k=3$. Construct two-dimensional biplots for:
+ Z1 and Z2
+ Z1 and Z3
+ Z2 and Z3

3. Can you give a meaningful interpretation to each dimension? 
Interpretation is crucial, quickly write this on a piece of paper and submit.

# Session info {-}

<details><summary>Session info</summary>

```{r session_info, echo=FALSE, cache=FALSE}
Sys.time()
sessioninfo::session_info()
```

</details>
